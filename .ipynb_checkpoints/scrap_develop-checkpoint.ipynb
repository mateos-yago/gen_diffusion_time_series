{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1341cae9-ab6b-44d1-8354-91954ff298cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Feb 13 22:02:33 2025\n",
    "\n",
    "@author: xing\n",
    "\"\"\"\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TimeSeriesDDPM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, T=1000):\n",
    "        super(TimeSeriesDDPM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim + 1, hidden_dim, batch_first=True)  # +1 for time embedding\n",
    "        self.fc = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "        # Noise schedule parameters\n",
    "        self.T = T\n",
    "        self.betas = torch.linspace(1e-4, 0.02, T)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        t = t[:, None, None].expand(-1, x.shape[1], 1)  # Expand t to match sequence shape\n",
    "        x = torch.cat((x, t), dim=-1)  # Concatenate t to input\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # Noise schedule functions\n",
    "    def q_sample(self, x0, t):\n",
    "        noise = torch.randn_like(x0)\n",
    "        sqrt_alpha_cumprod_t = torch.sqrt(self.alphas_cumprod[t])[:, None, None]\n",
    "        sqrt_one_minus_alpha_cumprod_t = torch.sqrt(1 - self.alphas_cumprod[t])[:, None, None]\n",
    "        return sqrt_alpha_cumprod_t * x0 + sqrt_one_minus_alpha_cumprod_t * noise, noise\n",
    "    \n",
    "    def p_sample(self, xt, t):\n",
    "        with torch.no_grad():\n",
    "            noise_pred = self(xt, t)\n",
    "            beta_t = self.betas[t][:, None, None]\n",
    "            alpha_t = self.alphas[t][:, None, None]\n",
    "            sqrt_recip_alpha_t = torch.sqrt(1.0 / alpha_t)\n",
    "            sqrt_one_minus_alpha_t = torch.sqrt(1 - alpha_t)\n",
    "            \n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(xt)\n",
    "            else:\n",
    "                noise = 0\n",
    "            \n",
    "            return sqrt_recip_alpha_t * (xt - beta_t / sqrt_one_minus_alpha_t * noise_pred) + noise\n",
    "\n",
    "    # Training function\n",
    "    def train_model(self, data, num_epochs=5, batch_size=10, learning_rate=1e-3):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        dataset = TensorDataset(data)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            for x0_batch in dataloader:\n",
    "                x0 = x0_batch[0].to(device)\n",
    "                t = torch.randint(0, self.T, (x0.shape[0],), device=device)\n",
    "                xt, noise = self.q_sample(x0, t)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                noise_pred = self(xt, t)\n",
    "                loss = F.mse_loss(noise_pred, noise)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Sampling function\n",
    "    def sample(self, seq_length, device):\n",
    "        self.eval()\n",
    "        x = torch.randn((1, seq_length, 1), device=device)  # Start with noise\n",
    "        for t in reversed(range(self.T)):\n",
    "            x = self.p_sample(x, torch.full((1,), t, device=device, dtype=torch.long))\n",
    "        return x.cpu().numpy()\n",
    "\n",
    "#######################################################################\n",
    "# Generate AR(1) synthetic time series\n",
    "def generate_ar1_series(num_series=100, seq_length=100, phi=0.8, sigma=0.1):\n",
    "    series = []\n",
    "    for _ in range(num_series):\n",
    "        x = [np.random.randn()]\n",
    "        for t in range(1, seq_length):\n",
    "            x.append(phi * x[-1] + sigma * np.random.randn())\n",
    "        series.append(x)\n",
    "    return torch.tensor(series, dtype=torch.float32).unsqueeze(-1)  # Add input_dim=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# Function to train the model and visualize results\n",
    "def train_and_plot():\n",
    "    # Initialize the model\n",
    "    model = TimeSeriesDDPM(input_dim=1, hidden_dim=32, T=1000)\n",
    "    \n",
    "    # Generate synthetic training data\n",
    "    data = generate_ar1_series()\n",
    "    \n",
    "    # Train the model\n",
    "    model.train_model(data, num_epochs=5)\n",
    "    \n",
    "    # Sample generated series\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    generated_series = model.sample(seq_length=data.shape[1], device=device)\n",
    "    \n",
    "    # Plotting the original and generated series\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Plot training data (first time series in the batch)\n",
    "    ax[0].plot(data[0].cpu().numpy(), label=\"Training Series\")\n",
    "    ax[0].set_title(\"Training Time Series\")\n",
    "    ax[0].set_xlabel(\"Time Steps\")\n",
    "    ax[0].set_ylabel(\"Value\")\n",
    "    \n",
    "    # Plot generated series\n",
    "    ax[1].plot(generated_series[0], label=\"Generated Series\", color='r')\n",
    "    ax[1].set_title(\"Generated Time Series\")\n",
    "    ax[1].set_xlabel(\"Time Steps\")\n",
    "    ax[1].set_ylabel(\"Value\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to train, generate, and plot\n",
    "train_and_plot()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
