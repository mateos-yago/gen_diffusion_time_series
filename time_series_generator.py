import torch
import numpy as np


class TimeSeriesGenerator:
    @staticmethod
    def generate_ar_series(num_series=100, seq_length=100, p=1, phi=0.8, sigma=0.1):
        """
        Generate an AR(p) series:
            x[t] = phi_1 * x[t-1] + phi_2 * x[t-2] + ... + phi_p * x[t-p] + sigma * noise,
        for t >= p. The first p values are initialized from N(0,1).

        Parameters:
            num_series (int): number of series to generate.
            seq_length (int): length of each time series.
            p (int): order of the AR process.
            phi (float or sequence): AR coefficients; if scalar, the same coefficient is used for all lags.
            sigma (float): standard deviation of the white noise.

        Returns:
            A torch.Tensor of shape (num_series, seq_length, 1).
        """
        # Ensure phi is a sequence of length p.
        if np.isscalar(phi):
            phi = [phi] * p
        else:
            phi = list(phi)
            if len(phi) != p:
                raise ValueError("phi must be a scalar or a sequence of length p")

        series = []
        for _ in range(num_series):
            # Initialize the first p values from a standard normal distribution.
            x = list(np.random.randn(p))
            for t in range(p, seq_length):
                # Compute the new value as the sum over the past p values weighted by phi
                # plus Gaussian noise.
                new_val = sum(phi[i] * x[t - i - 1] for i in range(p)) + sigma * np.random.randn()
                x.append(new_val)
            series.append(x)
        # Convert to a torch tensor and add an extra dimension for input_dim=1.
        return torch.tensor(series, dtype=torch.float32).unsqueeze(-1)

    @staticmethod
    def generate_arma_11_series(num_series=100, seq_length=100, phi=0.8, theta=0.5, sigma=0.1):
        """
        Generate ARMA(1,1) series:
            x[t] = phi * x[t-1] + e[t] + theta * e[t-1]
        where e[t] ~ N(0, sigma^2).
        """
        #TODO: review this function (it was autogenerated with CHATGPT)

        series = []
        for _ in range(num_series):
            # Generate noise sequence with one extra term for the MA part.
            e = np.random.randn(seq_length + 1) * sigma
            # Initialize with the first noise term.
            x = [e[0]]
            for t in range(1, seq_length):
                xt = phi * x[-1] + e[t] + theta * e[t - 1]
                x.append(xt)
            series.append(x)
        return torch.tensor(series, dtype=torch.float32).unsqueeze(-1)

    @staticmethod
    def generate_arima_series(num_series=100, seq_length=100, phi=0.8, theta=0.5, sigma=0.1, d=1):
        """
        Generate ARIMA series by first generating an ARMA process for the differences and then
        integrating (cumulatively summing) d times.

        For d=1, if diff[t] is ARMA(1,1):
            y[t] = y[t-1] + diff[t]
        """
        #TODO: review this function (it was autogenerated with CHATGPT)

        # First generate differences using the ARMA method.
        diff_series = TimeSeriesGenerator.generate_arma_11_series(num_series, seq_length, phi, theta, sigma)
        # Remove the last singleton dimension for integration.
        series = diff_series.squeeze(-1).numpy()
        # Integrate d times.
        for _ in range(d):
            series = np.cumsum(series, axis=1)
        return torch.tensor(series, dtype=torch.float32).unsqueeze(-1)

    @staticmethod
    def generate_garch_11_series(num_series=100, seq_length=100, omega=0.1, alpha=0.15, beta=0.8):
        """
        Generate GARCH(1,1) series:
            x[t] = sigma_t * e[t]    with e[t] ~ N(0,1)
            sigma_t^2 = omega + alpha * x[t-1]^2 + beta * sigma_{t-1}^2

        Uses the unconditional variance omega/(1 - alpha - beta) as the initial variance
        (if alpha+beta < 1).
        """
        #TODO: review this function (it was autogenerated with CHATGPT)
        series = []
        for _ in range(num_series):
            x_series = []
            # Set initial variance to the unconditional variance if the process is stationary.
            sigma2 = omega / (1 - alpha - beta) if (alpha + beta) < 1 else 1.0
            for t in range(seq_length):
                sigma_t = np.sqrt(sigma2)
                e_t = np.random.randn()
                x_t = sigma_t * e_t
                x_series.append(x_t)
                # Update variance for the next time step.
                sigma2 = omega + alpha * (x_t ** 2) + beta * sigma2
            series.append(x_series)
        return torch.tensor(series, dtype=torch.float32).unsqueeze(-1)

